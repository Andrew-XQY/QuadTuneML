{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a563bba6-aaf1-4fc3-ad73-e852c52ae0a0",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b268446f-eac8-45de-bdd2-7adfe7f41952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_x</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>sigma_x</th>\n",
       "      <th>sigma_y</th>\n",
       "      <th>emittance_x</th>\n",
       "      <th>emittance_y</th>\n",
       "      <th>transmission</th>\n",
       "      <th>klne.zqmd.0208</th>\n",
       "      <th>klne.zqmf.0209</th>\n",
       "      <th>klne.zqmd.0214</th>\n",
       "      <th>klne.zqmf.0215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788477</td>\n",
       "      <td>0.530907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257619</td>\n",
       "      <td>0.850309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.710011</td>\n",
       "      <td>0.533303</td>\n",
       "      <td>0.974789</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.991692</td>\n",
       "      <td>0.211019</td>\n",
       "      <td>0.888669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.658666</td>\n",
       "      <td>0.536753</td>\n",
       "      <td>0.928535</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.977697</td>\n",
       "      <td>0.297091</td>\n",
       "      <td>0.937314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.621333</td>\n",
       "      <td>0.539016</td>\n",
       "      <td>0.823964</td>\n",
       "      <td>0.050732</td>\n",
       "      <td>0.954580</td>\n",
       "      <td>0.370714</td>\n",
       "      <td>0.978204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.680710</td>\n",
       "      <td>0.527020</td>\n",
       "      <td>0.645524</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>0.894228</td>\n",
       "      <td>0.414992</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>0.602963</td>\n",
       "      <td>0.558957</td>\n",
       "      <td>0.146112</td>\n",
       "      <td>0.952870</td>\n",
       "      <td>0.427407</td>\n",
       "      <td>0.748595</td>\n",
       "      <td>0.411552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>0.612399</td>\n",
       "      <td>0.911240</td>\n",
       "      <td>0.137825</td>\n",
       "      <td>0.968324</td>\n",
       "      <td>0.412939</td>\n",
       "      <td>0.747879</td>\n",
       "      <td>0.285939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>0.647749</td>\n",
       "      <td>0.389005</td>\n",
       "      <td>0.130876</td>\n",
       "      <td>0.937929</td>\n",
       "      <td>0.400150</td>\n",
       "      <td>0.739845</td>\n",
       "      <td>0.170585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>0.647844</td>\n",
       "      <td>0.281590</td>\n",
       "      <td>0.129001</td>\n",
       "      <td>0.947957</td>\n",
       "      <td>0.387513</td>\n",
       "      <td>0.742203</td>\n",
       "      <td>0.091376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>0.663334</td>\n",
       "      <td>0.855640</td>\n",
       "      <td>0.126324</td>\n",
       "      <td>0.930842</td>\n",
       "      <td>0.381742</td>\n",
       "      <td>0.738360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14641 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_x    mean_y   sigma_x   sigma_y  emittance_x  emittance_y  \\\n",
       "0      0.788477  0.530907  1.000000  0.020799     1.000000     0.257619   \n",
       "1      0.710011  0.533303  0.974789  0.010109     0.991692     0.211019   \n",
       "2      0.658666  0.536753  0.928535  0.027253     0.977697     0.297091   \n",
       "3      0.621333  0.539016  0.823964  0.050732     0.954580     0.370714   \n",
       "4      0.680710  0.527020  0.645524  0.078637     0.894228     0.414992   \n",
       "...         ...       ...       ...       ...          ...          ...   \n",
       "14636  0.602963  0.558957  0.146112  0.952870     0.427407     0.748595   \n",
       "14637  0.612399  0.911240  0.137825  0.968324     0.412939     0.747879   \n",
       "14638  0.647749  0.389005  0.130876  0.937929     0.400150     0.739845   \n",
       "14639  0.647844  0.281590  0.129001  0.947957     0.387513     0.742203   \n",
       "14640  0.663334  0.855640  0.126324  0.930842     0.381742     0.738360   \n",
       "\n",
       "       transmission  klne.zqmd.0208  klne.zqmf.0209  klne.zqmd.0214  \\\n",
       "0          0.850309             0.0             0.0             0.0   \n",
       "1          0.888669             0.0             0.0             0.0   \n",
       "2          0.937314             0.0             0.0             0.0   \n",
       "3          0.978204             0.0             0.0             0.0   \n",
       "4          0.998299             0.0             0.0             0.0   \n",
       "...             ...             ...             ...             ...   \n",
       "14636      0.411552             1.0             1.0             1.0   \n",
       "14637      0.285939             1.0             1.0             1.0   \n",
       "14638      0.170585             1.0             1.0             1.0   \n",
       "14639      0.091376             1.0             1.0             1.0   \n",
       "14640      0.000000             1.0             1.0             1.0   \n",
       "\n",
       "       klne.zqmf.0215  \n",
       "0                 0.0  \n",
       "1                 0.1  \n",
       "2                 0.2  \n",
       "3                 0.3  \n",
       "4                 0.4  \n",
       "...               ...  \n",
       "14636             0.6  \n",
       "14637             0.7  \n",
       "14638             0.8  \n",
       "14639             0.9  \n",
       "14640             1.0  \n",
       "\n",
       "[14641 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "config = load_config(\"config.yaml\")\n",
    "\n",
    "# read all data sources, union into one long pd dataframe\n",
    "temp = load_tables(config['data_path'])\n",
    "df = merge_dfs(temp)\n",
    "data = pick_from_list_str(df, config['output_cols'], index=config['segment'])\n",
    "\n",
    "# convert all string to float\n",
    "data = convert_strings_to_float(data)\n",
    "\n",
    "# to log scale\n",
    "data = log_scale_df(data, config['log_cols'])\n",
    "\n",
    "# remove outliers (thresholding percentile)\n",
    "# data = add_valid_flag(data, config['longtail_cols'], config['outlier_threshold'])\n",
    "# data = data[data['valid'] == 1].drop(columns=['valid']).reset_index(drop=True)\n",
    "\n",
    "# normalized range\n",
    "data = normalize_min_max(data, config['output_cols']+config['input_cols'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e6641c-b66b-40f9-9b54-7c49075918b8",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b9702-8107-4357-bff7-3019677673a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "config = load_config(\"config.yaml\")\n",
    "\n",
    "# ——— Model ———\n",
    "def build_model(config):\n",
    "    inp = tf.keras.Input(shape=(len(config['input_cols']),))\n",
    "    \n",
    "    x = tf.keras.layers.Dense(256, use_bias=False)(inp)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(128, use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(128, use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(32, use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # linear output for full-range regression\n",
    "    out = tf.keras.layers.Dense(len(config['target_cols']))(x)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=config['learning_rate'])\n",
    "    model = tf.keras.Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=tf.keras.losses.Huber(),\n",
    "        # loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model(config)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84630a0d-e23f-4c72-9929-bac0047d4853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ——— Data prep ———\n",
    "X = data[config['input_cols']].to_numpy(dtype='float32')\n",
    "y = data[config['target_cols']].to_numpy(dtype='float32')\n",
    "\n",
    "n = X.shape[0]\n",
    "idx = tf.random.shuffle(tf.range(n), seed=config['seed'])\n",
    "n_test = int(config['test_size'] * n)\n",
    "n_val  = int(config['val_size']  * n)\n",
    "\n",
    "test_idx  = idx[:n_test]\n",
    "val_idx   = idx[n_test:n_test+n_val]\n",
    "train_idx = idx[n_test+n_val:]\n",
    "\n",
    "def make_ds(indices):\n",
    "    return (tf.data.Dataset\n",
    "              .from_tensor_slices((tf.gather(X, indices),\n",
    "                                   tf.gather(y, indices)))\n",
    "              .batch(config['batch_size'])\n",
    "              .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "train_ds, val_ds, test_ds = map(make_ds, (train_idx, val_idx, test_idx))\n",
    "\n",
    "\n",
    "# ——— Callbacks ———\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=config['patience'],\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=config['model_path'],\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ——— Train ———\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=config['epochs'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "model.save(config['model_path'])\n",
    "plot_history(history)\n",
    "\n",
    "# ——— Eval ———\n",
    "X_test = np.vstack([x for x, _ in test_ds])\n",
    "y_test = np.vstack([y for _, y in test_ds])\n",
    "\n",
    "# model predictions\n",
    "y_pred = model.predict(test_ds)\n",
    "\n",
    "# build and save dataframe\n",
    "df_out = pd.DataFrame(\n",
    "    np.hstack([X_test, y_test, y_pred]),\n",
    "    columns=(\n",
    "        config['input_cols']\n",
    "      + [f\"true_{c}\" for c in config['target_cols']]\n",
    "      + [f\"pred_{c}\" for c in config['target_cols']]\n",
    "    )\n",
    ")\n",
    "df_out.to_csv(config['save_to'] + \"test_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4457cb4-4613-4e0d-8d9e-0ba23380c962",
   "metadata": {},
   "source": [
    "## Training with different dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5b600f-0d1a-4d06-b106-7ff072a269cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ——— Data prep ———\n",
    "X_full = data[config['input_cols']].to_numpy(dtype='float32')\n",
    "y_full = data[config['target_cols']].to_numpy(dtype='float32')\n",
    "n_full = X_full.shape[0]\n",
    "\n",
    "# ——— fixed helpers ———\n",
    "def make_ds(X, y, indices):\n",
    "    return (tf.data.Dataset\n",
    "              .from_tensor_slices((tf.gather(X, indices),\n",
    "                                   tf.gather(y, indices)))\n",
    "              .batch(config['batch_size'])\n",
    "              .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=config['patience'],\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=config['model_path'],\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ——— subsample loop ———\n",
    "final_results = []\n",
    "for p in range(100, 0, -5):                # 100, 95, …, 5%\n",
    "    m = int(n_full * p / 100)             # samples to use\n",
    "    sub_idx = tf.random.shuffle(tf.range(n_full), seed=config['seed'])[:m]\n",
    "    X, y = tf.gather(X_full, sub_idx), tf.gather(y_full, sub_idx)\n",
    "\n",
    "    # shuffle & split\n",
    "    n = m\n",
    "    idx = tf.random.shuffle(tf.range(n), seed=config['seed'])\n",
    "    n_test = int(config['test_size'] * n)\n",
    "    n_val  = int(config['val_size']  * n)\n",
    "\n",
    "    test_idx  = idx[:n_test]\n",
    "    val_idx   = idx[n_test:n_test+n_val]\n",
    "    train_idx = idx[n_test+n_val:]\n",
    "\n",
    "    train_ds = make_ds(X, y, train_idx)\n",
    "    val_ds   = make_ds(X, y, val_idx)\n",
    "    test_ds  = make_ds(X, y, test_idx)\n",
    "\n",
    "    # train\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=config['epochs'],\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    plot_history(history)\n",
    "\n",
    "    # eval\n",
    "    X_test = np.vstack([x for x, _ in test_ds])\n",
    "    y_test = np.vstack([y for _, y in test_ds])\n",
    "    y_pred = model.predict(test_ds)\n",
    "\n",
    "    # save with sample size in filename\n",
    "    df_out = pd.DataFrame(\n",
    "        np.hstack([X_test, y_test, y_pred]),\n",
    "        columns=(\n",
    "            config['input_cols']\n",
    "          + [f\"true_{c}\" for c in config['target_cols']]\n",
    "          + [f\"pred_{c}\" for c in config['target_cols']]\n",
    "        )\n",
    "    )\n",
    "    out_path = f\"{config['save_to']}test_results_{m}.csv\"\n",
    "    df_out.to_csv(out_path, index=False)\n",
    "    print(f\"p={p}% ({m} samples) → saved to {out_path}\")\n",
    "    \n",
    "    dic = metrics(y_test.mean(axis=1),y_pred.mean(axis=1))\n",
    "    final_results.append(merge_dicts(dic, {\"sample_number\": m}))\n",
    "\n",
    "    model = build_model(config)\n",
    "\n",
    "def convert(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    return obj\n",
    "\n",
    "# Recursively process the list of dicts\n",
    "cleaned_data = [{k: convert(v) for k, v in d.items()} for d in final_results]\n",
    "\n",
    "with open(\"sample_efficiency.json\", \"w\") as f:\n",
    "    json.dump(cleaned_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a96e0-fc00-4e43-8493-2f715c26b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from APS_PLOT_STYLE import *\n",
    "\n",
    "set_aps_single_column(scale=2.1)\n",
    "\n",
    "\n",
    "# APS-style colors\n",
    "COLORS = {\n",
    "    'MAE': '#56B4E9',   # sky blue\n",
    "    'RMSE': '#E69F00',  # orange\n",
    "    'R2': '#009E73',    # bluish green\n",
    "}\n",
    "\n",
    "\n",
    "def plot_key_lines(data_list, y_keys, x_key, margin_frac=0.05):\n",
    "    # sort by x\n",
    "    sorted_data = sorted(data_list, key=lambda d: d[x_key])\n",
    "    # scale x by 0.8\n",
    "    x = [d[x_key] * 0.8 for d in sorted_data]\n",
    "\n",
    "    # which keys go where\n",
    "    left_keys  = [k for k in ['MAE', 'RMSE'] if k in y_keys]\n",
    "    right_keys = [k for k in ['R2']     if k in y_keys]\n",
    "\n",
    "    # scale left errors to percent immediately\n",
    "    left_vals  = [[d[k]*100 for d in sorted_data] for k in left_keys]\n",
    "    right_vals = [[d[k]     for d in sorted_data] for k in right_keys]\n",
    "\n",
    "    def limits(vals):\n",
    "        vmin, vmax = min(min(v) for v in vals), max(max(v) for v in vals)\n",
    "        vr = vmax - vmin\n",
    "        return vmin - margin_frac*vr, vmax + margin_frac*vr\n",
    "\n",
    "    left_lim  = limits(left_vals)  if left_vals  else None\n",
    "    right_lim = limits(right_vals) if right_vals else None\n",
    "\n",
    "    # make figure larger\n",
    "    fig, ax_l = plt.subplots(figsize=(10, 6))\n",
    "    ax_r = ax_l.twinx() if right_lim else None\n",
    "\n",
    "    markers = ['o', 's']\n",
    "    # plot left (%)\n",
    "    for i, k in enumerate(left_keys):\n",
    "        ax_l.plot(x, left_vals[i],\n",
    "                  marker=markers[i],\n",
    "                  markersize=7,\n",
    "                  label=k,\n",
    "                  color=COLORS[k])\n",
    "    if left_lim:\n",
    "        ax_l.set_ylim(*left_lim)\n",
    "\n",
    "    # plot right (with math‑style label)\n",
    "    if ax_r:\n",
    "        k = right_keys[0]\n",
    "        ax_r.plot(x, right_vals[0],\n",
    "                  marker='^',\n",
    "                  markersize=7,\n",
    "                  label=r'$R^2$',\n",
    "                  color=COLORS[k])\n",
    "        ax_r.set_ylim(*right_lim)\n",
    "\n",
    "    ax_l.set_xlabel('Number of samples')\n",
    "    ax_l.set_ylabel('Error (%)')\n",
    "    if ax_r:\n",
    "        ax_r.set_ylabel('R²')\n",
    "\n",
    "    # combined legend\n",
    "    hl, ll = ax_l.get_legend_handles_labels()\n",
    "    if ax_r:\n",
    "        hr, lr = ax_r.get_legend_handles_labels()\n",
    "        ax_l.legend(hl+hr, ll+lr,\n",
    "                    loc='upper right',\n",
    "                    bbox_to_anchor=(0.97, 0.88))\n",
    "    else:\n",
    "        ax_l.legend(hl, ll,\n",
    "                    loc='upper right',\n",
    "                    bbox_to_anchor=(0.97, 0.88))\n",
    "\n",
    "    # vertical line at scaled threshold\n",
    "    raw_thresh = 6588\n",
    "    thresh = int(raw_thresh * 0.8)\n",
    "    ax_l.axvline(thresh, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "    # compute a 2% offset in data‐coords\n",
    "    x_off = thresh * 0.05\n",
    "\n",
    "    # math‑style label for the line\n",
    "    ax_l.text(\n",
    "        thresh + x_off,\n",
    "        0.5,\n",
    "        rf'$x\\!=\\!{int(thresh)}$',\n",
    "        # r'x = 5270',\n",
    "        transform=ax_l.get_xaxis_transform(),\n",
    "        ha='left', va='top',\n",
    "        # fontsize=10, \n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig('sample_efficiency.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_key_lines(final_results, y_keys=[\"RMSE\",\"MAE\",\"R2\"], x_key=\"sample_number\", margin_frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643baff-1455-4605-ad8c-ff5d78cf9e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "598adcb4-ae31-4413-83bb-a9253561a8ec",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec9441-81a0-43e5-a776-a7275a084360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from functools import partial\n",
    "from APS_PLOT_STYLE import *\n",
    "\n",
    "set_aps_single_column(scale=2.2)\n",
    "\n",
    "# preset by keyword\n",
    "# emittance_x 0.03\n",
    "# emittance_y 0.05\n",
    "new_func = partial(plot_true_vs_pred, rng=0.052)\n",
    "funcs = [new_func, plot_error_distribution]\n",
    "\n",
    "config = load_config(\"config.yaml\")\n",
    "result = pd.read_csv(config['save_to']+\"test_results.csv\")\n",
    "result = clip_df(result)\n",
    "process_df(result, inputs=config['input_cols'], outputs=config['target_cols'], save_to=config['save_to'], funcs=funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11630bb6-0f85-4bf5-b815-81fb55156951",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b4e13-14f2-47aa-a22b-bcf2fc090e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distributions(data, bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caeeb5c-ac19-435b-872a-9a0fb0aa8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "config = load_config(\"config.yaml\")\n",
    "\n",
    "\n",
    "temp = []\n",
    "for i in range(8):\n",
    "    df = pd.read_csv(config['data_path'])\n",
    "    data = pick_from_list_str(df, config['output_cols'], index=i)\n",
    "    data = convert_strings_to_float(data)\n",
    "    temp.append(data)\n",
    "min_d, max_d = compute_bounds(temp)\n",
    "\n",
    "temp = []\n",
    "for i in range(8):\n",
    "    df = pd.read_csv(config['data_path'])\n",
    "    data = pick_from_list_str(df, config['output_cols'], index=i)\n",
    "    data = convert_strings_to_float(data)\n",
    "    temp.append(plot_distributions(data, bins=200, min_bounds=min_d, max_bounds=max_d, title=f'segment_{i+1}'))\n",
    "\n",
    "figures_to_gif(temp, config['save_to'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4886a5e9-2562-406d-864a-52b716c3f2c6",
   "metadata": {},
   "source": [
    "## system’s stability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc44c2-4bb2-4905-b467-4300a5f51979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "config = load_config(\"config.yaml\")\n",
    "\n",
    "def std(values: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the 1σ standard deviation of a list of numbers,\n",
    "    using N in the denominator (population formula).\n",
    "    \"\"\"\n",
    "    n = len(values)\n",
    "    if n == 0:\n",
    "        raise ValueError(\"Empty list: no values to compute std.\")\n",
    "    mean = sum(values) / n\n",
    "    variance = sum((x - mean) ** 2 for x in values) / n\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def range_of_list(values):\n",
    "    \"\"\"\n",
    "    Returns max(values) - min(values), or None for an empty list.\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        return None\n",
    "    return max(values) - min(values)\n",
    "\n",
    "df = pd.read_csv('data/batch_results_2.csv')\n",
    "data = pick_from_list_str(df, config['output_cols'], index=config['segment'])\n",
    "data = convert_strings_to_float(data)\n",
    "data = log_scale_df(data, config['log_cols'])\n",
    "data = normalize_min_max(data, config['output_cols']+config['input_cols'])\n",
    "\n",
    "for i in ['emittance_x', 'emittance_y']:\n",
    "    temp = []\n",
    "    for j in range(int(df['index'].max())+1):\n",
    "        sigma = range_of_list(data[data['index'] == j][i].tolist())\n",
    "        temp.append(sigma)\n",
    "    print(' '.join([i, str(max(temp))]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
